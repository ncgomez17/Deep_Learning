{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aprendiendo_Keras4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPl9HG08Cap9gRzX8w+34ec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ncgomez17/Deep_Learning/blob/master/Keras/Aprendiendo_Keras4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KiSOBSyYsSB"
      },
      "source": [
        "En este ejemplo utilizaremos el mismo conjunto de datos que en **Aprendiendo_Keras3** pero esta vez lo implementaremos con redes neuronales convolucionales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA2fPtMHY72Y",
        "outputId": "93e5dc31-a47f-4697-d419-069ef537a54e"
      },
      "source": [
        "## Cargamos los datos y los preparamos para la red neuronal\r\n",
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "print(tf.__version__)\r\n",
        "\r\n",
        "fashion_mnist = keras.datasets.fashion_mnist\r\n",
        "\r\n",
        "(train_images, train_labels) , (test_images, test_labels) = fashion_mnist.load_data()\r\n",
        "\r\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress' , 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "\r\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\r\n",
        "train_images = train_images.astype('float32')/255\r\n",
        "\r\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\r\n",
        "test_images = test_images.astype('float32')/255"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6CFEDDOa0Vv"
      },
      "source": [
        "Cabe destacar que en la red neuronal convolucional se esperaun tensor de 3D y por ello hemos hecho un reshape del tensor 2D añadiendo una dimensión."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXbtwnSHcQqE"
      },
      "source": [
        "##Vamos probar creando una red neuronal con 2 tipos de capas que aún no he visto (Dropout,BatchNormalization)\r\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import MaxPooling2D\r\n",
        "from keras import models\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),\r\n",
        "                 activation='relu', strides=1, padding='same',\r\n",
        "                 input_shape=(28,28,1)))\r\n",
        "model.add(BatchNormalization())\r\n",
        "\r\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),\r\n",
        "                 activation='relu', strides=1, padding='same'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),\r\n",
        "                 activation='relu', strides=1, padding='same'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3),\r\n",
        "                 activation='relu', strides=1, padding='same'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.25))\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(512, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcYN_JLrf7Hs"
      },
      "source": [
        "La capa **BatchNormalization** usa una técnica que se encarga de normalizar las entradas de la capa de tal manera que tengan una activación de salidamedia de cero y una desviación estándar de uno.\r\n",
        "La capa **Dropout** aplica una técnica queayuda a mitigar el sobreajuste de los modelos.Se basa en ignorar ciertos conjuntos de neuronas de la red durante la fase de entrenamiento de manera aleatoria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESS_AqXjgmqJ",
        "outputId": "0dc0dcf5-5650-4d4d-d917-500df07802c1"
      },
      "source": [
        "## Añadimos los hiperparámetros\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(train_images,train_labels,epochs=5)\r\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\r\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 612s 326ms/step - loss: 0.6790 - accuracy: 0.7707\n",
            "Epoch 2/5\n",
            " 296/1875 [===>..........................] - ETA: 8:30 - loss: 0.3265 - accuracy: 0.8864"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEvilakhhWcN"
      },
      "source": [
        "Como podemos observar el cálculo para el entrenamiento se hace mucho más lento pero la tasa de acierto mejora bastante.\r\n",
        "\r\n"
      ]
    }
  ]
}